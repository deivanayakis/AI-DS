{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set=pd.read_csv('/kaggle/input/heart-disease-dataset-uci/HeartDiseaseTrain-Test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set['sex'] = data_set['sex'].map({'Male': 1, 'Female': 0})\ndata_set['chest_pain_type'] = data_set['chest_pain_type'].map({'Typical angina': 1, 'Atypical angina': 2,'Non-anginal':3,'Asymptomatic':4})\ndata_set['fasting_blood_sugar'] = data_set['fasting_blood_sugar'].map({'Lower than 120 mg/ml': 0, 'Greater than 120 mg/ml': 1})\ndata_set['rest_ecg'] = data_set['rest_ecg'].map({'Normal': 0, 'ST-T wave abnormality': 1,'Left ventricular hypertrophy':2})\ndata_set['exercise_induced_angina'] = data_set['exercise_induced_angina'].map({'Yes': 0, 'No': 1})\ndata_set['slope'] = data_set['slope'].map({'Upsloping': 0, 'Downsloping': 1,'Flat':2})\ndata_set['vessels_colored_by_flourosopy'] = data_set['vessels_colored_by_flourosopy'].map({'Zero': 0, 'One': 1,'Two':2,'Three':3})\ndata_set['thalassemia'] = data_set['thalassemia'].map({'Reversable Defect': 0, 'Fixed Defect': 1})\ndata_set.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set['chest_pain_type'] = data_set['chest_pain_type'].fillna(99999)\ndata_set['vessels_colored_by_flourosopy'] = data_set['vessels_colored_by_flourosopy'].fillna(99999)\ndata_set['thalassemia'] = data_set['thalassemia'].fillna(99999)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_set.drop('target', axis = 1)\ny=data_set['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DECISION TREE\nfrom sklearn.tree import DecisionTreeClassifier  \nclassifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  \nclassifier.fit(X_train, y_train)\nDTy_pred= classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HYBRID(RF AND SVM)\nestimators = []\nfrom sklearn.svm import SVC\nclassifier1 = SVC(kernel='linear', random_state=0)\nestimators.append(('svm', classifier1))\nfrom sklearn.ensemble import RandomForestClassifier  \nclassifier2= RandomForestClassifier(n_estimators= 20, criterion=\"entropy\")\nestimators.append(('rf', classifier2))\nfrom sklearn.ensemble import VotingClassifier\nensemble = VotingClassifier(estimators)\nensemble.fit(X_train, y_train)\nHy_pred = ensemble.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RANDOM FOREST\nfrom sklearn.ensemble import RandomForestClassifier  \nclassifier= RandomForestClassifier(n_estimators= 20, criterion=\"entropy\")  \nclassifier.fit(X_train, y_train) \nRFy_pred= classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SUPPORT VECTOR MACHINE\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='linear', random_state=0) \nclassifier.fit(X_train, y_train) \nSVMy_pred= classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOGISTIC REGRESSION\nfrom sklearn.linear_model import LogisticRegression  \nclassifier= LogisticRegression(random_state=0)  \nclassifier.fit(X_train, y_train)\nLRy_pred= classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#K NEAREST NEIGHBOR\nfrom sklearn.neighbors import KNeighborsClassifier  \nclassifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \nclassifier.fit(X_train, y_train) \nKNNy_pred= classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\na=int(accuracy_score(y_test,DTy_pred)*100)\nb=int(accuracy_score(y_test,Hy_pred)*100)\nc=int(accuracy_score(y_test,RFy_pred)*100)\nd=int(accuracy_score(y_test,SVMy_pred)*100)\ne=int(accuracy_score(y_test,LRy_pred)*100)\nf=int(accuracy_score(y_test,KNNy_pred)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_axis=[2,3,4,5,6,7]\ny_axis=[a,b,c,d,e,f]\nlabels=['DT','HYBRID','RF','SVM','LR','KNN']\nx = np.arange(len(x_axis)) # the label locations\nwidth = 0.35 # the width of the bars\n\nfig, ax = plt.subplots()\n\nax.set_ylabel('Accuracy')\nax.set_xlabel('Ml')\nax.set_title('ML ALGORITHM')\nax.set_xticks(x)\nplt.xticks(x_axis,labels)\n\npps = ax.bar(x - width/2, y_axis, width, label='ML')\nfor p in pps:\n   height = p.get_height()\n   ax.annotate('{}'.format(height),\n      xy=(p.get_x() + p.get_width() / 2, height),\n      xytext=(0, 3), # 3 points vertical offset\n      textcoords=\"offset points\",\n      ha='center', va='bottom')\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}